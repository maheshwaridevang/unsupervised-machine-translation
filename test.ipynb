{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import sacrebleu\n",
    "import torch\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "model_checkpoint_path = \"en_to_fr_model_checkpoint\"  # Path to your saved model\n",
    "saved_model = MarianMTModel.from_pretrained(model_checkpoint_path).to(\"cuda\")\n",
    "saved_tokenizer = MarianTokenizer.from_pretrained(model_checkpoint_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load sentences from a file\n",
    "def load_sentences(file_path, num_sentences=None):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        sentences = [line.strip() for line in file]\n",
    "    if num_sentences:\n",
    "        sentences = sentences[:num_sentences]\n",
    "    return sentences\n",
    "\n",
    "# Translate a batch of sentences\n",
    "def translate_batch_batched(sentences, model, tokenizer, batch_size=16, max_length=128):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch_sentences = sentences[i:i + batch_size]\n",
    "        inputs = tokenizer(\n",
    "            batch_sentences,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=max_length,\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        input_ids = inputs[\"input_ids\"].to(\"cuda\")\n",
    "        attention_mask = inputs[\"attention_mask\"].to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=max_length\n",
    "            )\n",
    "        batch_predictions = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "        all_predictions.extend(batch_predictions)\n",
    "\n",
    "    return all_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate BLEU, METEOR, and TER scores\n",
    "def evaluate_model(predictions, targets):\n",
    "    # Tokenize the references and predictions for METEOR\n",
    "    tokenized_references = [[ref.split()] for ref in targets]  # Nested list for BLEU\n",
    "    tokenized_hypotheses = [hyp.split() for hyp in predictions]\n",
    "\n",
    "    # BLEU Score\n",
    "    bleu_score = corpus_bleu(tokenized_references, tokenized_hypotheses)\n",
    "\n",
    "    # METEOR Score\n",
    "    meteor_scores = [\n",
    "        meteor_score([ref.split()], hyp.split())\n",
    "        for ref, hyp in zip(targets, predictions)\n",
    "    ]\n",
    "    avg_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
    "\n",
    "    # TER Score\n",
    "    ter = sacrebleu.corpus_ter(predictions, [targets])\n",
    "\n",
    "    print(f\"BLEU Score: {bleu_score * 100:.2f}\")\n",
    "    print(f\"METEOR Score: {avg_meteor_score:.2f}\")\n",
    "    print(f\"TER Score: {ter.score:.2f}\")\n",
    "\n",
    "    return bleu_score, avg_meteor_score, ter.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'predictions.fr'.\n"
     ]
    }
   ],
   "source": [
    "# Main script\n",
    "source_file = \"europarl-v7.fr-en.en\"  # File containing source sentences\n",
    "target_file = \"europarl-v7.fr-en.fr europarl-v7.fr-en.en\"  # File containing target sentences\n",
    "predictions_file = \"predictions.fr\"  # File to save predictions\n",
    "num_sentences = 1500  # Limit to first 1500 sentences\n",
    "\n",
    "# Load source and target sentences\n",
    "source_sentences = load_sentences(source_file, num_sentences=num_sentences)\n",
    "target_sentences = load_sentences(target_file, num_sentences=num_sentences)\n",
    "\n",
    "# Translate source sentences\n",
    "predictions = translate_batch_batched(source_sentences, saved_model, saved_tokenizer)\n",
    "\n",
    "# Save predictions to file\n",
    "with open(predictions_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    for prediction in predictions:\n",
    "        file.write(prediction + \"\\n\")\n",
    "print(f\"Predictions saved to '{predictions_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 13.89\n",
      "METEOR Score: 0.32\n",
      "TER Score: 77.75\n"
     ]
    }
   ],
   "source": [
    "bleu, meteor, ter = evaluate_model(predictions, target_sentences)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
